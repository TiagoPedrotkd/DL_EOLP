{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adc9de4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #7B61FF; color:white; padding:20px; border-radius:10px; font-family:Arial, sans-serif; text-align:center; font-size:28px; font-weight:bold;\">\n",
    "  ğŸ§± 02 â€“ Baseline Model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630b7cb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; color:white; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Import Libraries and Define Paths</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p style=\"font-size:18px;\">This is the initial block of the rare species image classification project.</p>\n",
    "\n",
    "  <p>In this section, we perform the following tasks:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li>ğŸ“ <strong>Import libraries</strong> for data manipulation (<code>pandas</code>), file paths (<code>pathlib</code>), and image processing (<code>PIL</code>).</li>\n",
    "    <li>ğŸ–¼ï¸ <strong>Apply visual styling</strong> using <code>matplotlib</code> and <code>seaborn</code> to ensure clean and consistent plots.</li>\n",
    "    <li>ğŸ“‚ <strong>Define the main project directories</strong>, including image folders and the metadata CSV file.</li>\n",
    "    <li>âœ… <strong>Automatic path validation</strong> to ensure all required files and directories exist.</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>This setup provides a reliable foundation for safely loading and exploring the dataset.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== ğŸ“¦ Importar bibliotecas essenciais ==========================================\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827ce013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== ğŸ“‚ Definir caminhos principais do projeto ==========================================\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'output'\n",
    "LOGS_DIR = OUTPUTS_DIR / 'logs'\n",
    "PREDICTIONS_DIR = OUTPUTS_DIR / 'predictions'\n",
    "TRAIN_DIR = PROCESSED_DIR / 'train'\n",
    "VAL_DIR = PROCESSED_DIR / 'val'\n",
    "TEST_DIR = PROCESSED_DIR / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67981f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; color:white; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Define Parameters</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p>In this section, we define the core parameters that will guide the training process of the model. These include the input image size, batch size, number of training epochs, and the directory structure of the dataset.</p>\n",
    "  \n",
    "  <p>Setting these values early ensures consistency across all steps and allows for easier adjustments when experimenting with different model architectures or datasets.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29236772",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950670d7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; color:white; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Simple CNN Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p>This block defines a basic Convolutional Neural Network (CNN) architecture used as a starting point for image classification.</p>\n",
    "\n",
    "  <p>The model was built using three convolutional layers followed by max pooling, a flatten layer, a dense layer with ReLU activation, and dropout for regularization. This structure is intentionally simple, serving as a strong baseline for comparing the performance of more complex models.</p>\n",
    "\n",
    "  <p>All outputs â€” including the trained model, training logs, accuracy plots, confusion matrix, predictions, and classification reports â€” were automatically saved in their respective folders: <code>/models</code>, <code>/output</code>, <code>/reports</code>, and <code>/reports/figures</code>.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36b9f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn_pipeline(train_dir, val_dir, test_dir, model_name=\"cnn_baseline\", image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, epochs=EPOCHS):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = REPORTS_DIR / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = datagen.flow_from_directory(train_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
    "    val_generator = datagen.flow_from_directory(val_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
    "    test_generator = datagen.flow_from_directory(test_dir, target_size=image_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(train_generator, validation_data=val_generator, epochs=epochs,\n",
    "                        callbacks=[csv_logger, early_stop, reduce_lr])\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_path_weights = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_path_weights)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        top_20[[\"precision\", \"recall\", \"f1-score\"]],\n",
    "        annot=True, fmt=\".2f\", cmap=\"YlGnBu\",\n",
    "        linewidths=0.5, annot_kws={\"size\": 9}\n",
    "    )\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a3f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8627 images belonging to 202 classes.\n",
      "Found 2157 images belonging to 202 classes.\n",
      "Found 1199 images belonging to 202 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 191ms/step - accuracy: 0.0257 - loss: 5.2228 - val_accuracy: 0.0751 - val_loss: 4.8675 - learning_rate: 5.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 179ms/step - accuracy: 0.0716 - loss: 4.8511 - val_accuracy: 0.1015 - val_loss: 4.6281 - learning_rate: 5.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 179ms/step - accuracy: 0.1118 - loss: 4.5145 - val_accuracy: 0.1307 - val_loss: 4.4781 - learning_rate: 5.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - accuracy: 0.1699 - loss: 4.0462 - val_accuracy: 0.1539 - val_loss: 4.3916 - learning_rate: 5.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - accuracy: 0.2393 - loss: 3.5113 - val_accuracy: 0.1567 - val_loss: 4.4241 - learning_rate: 5.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 185ms/step - accuracy: 0.3394 - loss: 2.8786 - val_accuracy: 0.1641 - val_loss: 4.6753 - learning_rate: 5.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.4412 - loss: 2.2897\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 182ms/step - accuracy: 0.4411 - loss: 2.2898 - val_accuracy: 0.1729 - val_loss: 5.0235 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 181ms/step - accuracy: 0.5448 - loss: 1.7660 - val_accuracy: 0.1743 - val_loss: 5.4502 - learning_rate: 2.5000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m270/270\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - accuracy: 0.6170 - loss: 1.4332 - val_accuracy: 0.1803 - val_loss: 5.8644 - learning_rate: 2.5000e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.1559 - loss: 4.3554\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 668ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\cnn_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\cnn_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\cnn_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (PNG):        D:\\Repositories\\DL_EOLP\\reports\\figures\\cnn_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\cnn_baseline_predictions.csv\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\cnn_baseline_accuracy_plot.png\n",
      "ğŸ“‰ Confusion matrix:            D:\\Repositories\\DL_EOLP\\reports\\figures\\cnn_baseline_confusion_matrix.png\n",
      "âœ… Final validation accuracy:   15.39%\n"
     ]
    }
   ],
   "source": [
    "results = run_cnn_pipeline(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    val_dir=VAL_DIR,\n",
    "    test_dir=TEST_DIR,\n",
    "    model_name=\"cnn_baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c9e78",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; color:white; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ§ª CNN Baseline â€“ Final Results Summary</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;line-height: 2.0\"> \n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“Œ Model Description</h2>\n",
    "  <p>\n",
    "    The baseline model consists of a simple Convolutional Neural Network (CNN) with 3 <code>Conv2D + MaxPooling</code> blocks, followed by a fully connected <code>Dense</code> layer and <code>Dropout</code> for regularization. The final layer uses <code>softmax</code> activation for multi-class prediction.\n",
    "  </p>\n",
    "  <p>\n",
    "    The model was trained with <strong>EarlyStopping</strong> and <strong>ReduceLROnPlateau</strong> over <strong>9 epochs</strong>.\n",
    "  </p>\n",
    "\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“Š Performance Overview</h2>\n",
    "  <ul>\n",
    "    <li><strong>Final Training Accuracy:</strong> ~61%</li>\n",
    "    <li><strong>Final Validation Accuracy:</strong> ~18%</li>\n",
    "    <li><span style=\"color: orange;\"><strong>Observation:</strong> Overfitting detected â€” the gap between training and validation accuracy suggests poor generalization.</span></li>\n",
    "  </ul>\n",
    "  <img src=\"../reports/figures/cnn_baseline_accuracy_plot.png\" alt=\"Training vs Validation Accuracy\" width=\"600\"/>\n",
    "\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“ˆ Classification Report</h2>\n",
    "  <p>The model struggles to perform well across most classes. Only a few classes show acceptable precision or recall values.</p>\n",
    "  <p><strong>Full Report Heatmap:</strong></p>\n",
    "  <img src=\"../reports/figures/cnn_baseline_classification_report_heatmap.png\" alt=\"Classification Report\" width=\"700\"/>\n",
    "\n",
    "  <p><strong>Top 20 Classes Heatmap:</strong></p>\n",
    "  <img src=\"../reports/figures/cnn_baseline_classification_report_heatmap_top20.png\" alt=\"Top 20 Classification Report\" width=\"600\"/>\n",
    "\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“‰ Confusion Matrix</h2>\n",
    "  <p>The full matrix is unreadable due to the number of classes. The Top 20 version provides clearer insights.</p>\n",
    "  <p><strong>Full Confusion Matrix:</strong></p>\n",
    "  <img src=\"../reports/figures/cnn_baseline_confusion_matrix.png\" alt=\"Full Confusion Matrix\" width=\"700\"/>\n",
    "\n",
    "  <p><strong>Top 20 Confusion Matrix:</strong></p>\n",
    "  <img src=\"../reports/figures/cnn_baseline_confusion_matrix_top20.png\" alt=\"Top 20 Confusion Matrix\" width=\"600\"/>\n",
    "\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ’¾ Files and Artifacts Saved</h2>\n",
    "  <ul>\n",
    "    <li>ğŸ“ <code>models/cnn_baseline.h5</code></li>\n",
    "    <li>ğŸ“ <code>models/cnn_baseline.weights.h5</code></li>\n",
    "    <li>ğŸ“„ <code>output/logs/cnn_baseline_training_log.csv</code></li>\n",
    "    <li>ğŸ“Š <code>reports/cnn_baseline_classification_report.csv</code></li>\n",
    "    <li>ğŸ§¾ <code>output/predictions/cnn_baseline_predictions.csv</code></li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
