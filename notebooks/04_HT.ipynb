{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057bbc14",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #FF8C42; padding:20px; border-radius:10px; font-family:Arial, sans-serif; text-align:center; font-size:28px; font-weight:bold;\">\n",
    "  ‚öôÔ∏è 04 ‚Äì Hyperparameter Tuning\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600257f8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üì¶ Import Libraries and Define Paths</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p style=\"font-size:18px;\">This is the initial block of the rare species image classification project.</p>\n",
    "\n",
    "  <p>In this section, we perform the following tasks:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li>üìÅ <strong>Import libraries</strong> for data manipulation (<code>pandas</code>), file paths (<code>pathlib</code>), and image processing (<code>PIL</code>).</li>\n",
    "    <li>üñºÔ∏è <strong>Apply visual styling</strong> using <code>matplotlib</code> and <code>seaborn</code> to ensure clean and consistent plots.</li>\n",
    "    <li>üìÇ <strong>Define the main project directories</strong>, including image folders and the metadata CSV file.</li>\n",
    "    <li>‚úÖ <strong>Automatic path validation</strong> to ensure all required files and directories exist.</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>This setup provides a reliable foundation for safely loading and exploring the dataset.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82830fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193efc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'output'\n",
    "LOGS_DIR = OUTPUTS_DIR / 'logs'\n",
    "PREDICTIONS_DIR = OUTPUTS_DIR / 'predictions'\n",
    "TRAIN_DIR = PROCESSED_DIR / 'train'\n",
    "VAL_DIR = PROCESSED_DIR / 'val'\n",
    "TEST_DIR = PROCESSED_DIR / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034564d4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üì¶ Define Parameters</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p>In this section, we define the core parameters that will guide the training process of the model. These include the input image size, batch size, number of training epochs, and the directory structure of the dataset.</p>\n",
    "  \n",
    "  <p>Setting these values early ensures consistency across all steps and allows for easier adjustments when experimenting with different model architectures or datasets.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dafeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eae14d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üìÇ Load and Prepare the Dataset</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "  <p>This section is responsible for loading the processed dataset and preparing it for training and evaluation.</p>\n",
    "\n",
    "  <p>Using <code>ImageDataGenerator</code>, the images are normalized (pixel values scaled between 0 and 1), and loaded in batches directly from the respective folders for:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li><strong>üü¢ Training set</strong> ‚Äî used to update model weights during learning</li>\n",
    "    <li><strong>üü† Validation set</strong> ‚Äî used to monitor generalization and prevent overfitting</li>\n",
    "    <li><strong>üîµ Test set</strong> ‚Äî used for final evaluation after training</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>The dataset is expected to be organized in subfolders where each folder represents one class label.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae733941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8462 images belonging to 202 classes.\n",
      "Found 4292 images belonging to 202 classes.\n",
      "Found 1199 images belonging to 202 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_generator = datagen.flow_from_directory(VAL_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_generator = datagen.flow_from_directory(TEST_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "NUM_CLASSES = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9daea",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üìÇ Balance Weights</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f207971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.classes\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28d9fa",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">‚öôÔ∏è Set Up Hyperparameter Ranges for MobileNetV2</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631fafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenetv2(hp):\n",
    "    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(hp.Int('units1', min_value=128, max_value=1024, step=64), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout1', 0.3, 0.6, step=0.1)))\n",
    "\n",
    "    model.add(Dense(hp.Int('units2', min_value=64, max_value=512, step=64), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout2', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    lr = hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413060f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from D:\\Repositories\\DL_EOLP\\output\\logs\\tuner_logs\\mobilenetv2_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_mobilenetv2,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=EPOCHS,\n",
    "    factor=3,\n",
    "    directory= LOGS_DIR / 'tuner_logs',\n",
    "    project_name='mobilenetv2_tuning'\n",
    ")\n",
    "\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb394b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Melhores hiperpar√¢metros encontrados:\n",
      "{'units1': 640, 'dropout1': 0.4, 'units2': 512, 'dropout2': 0.30000000000000004, 'learning_rate': 0.0001, 'tuner/epochs': 40, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparams = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Melhores hiperpar√¢metros encontrados:\")\n",
    "print(best_hyperparams.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87352770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mobilenetv2_tuned_pipeline(train_gen, val_gen, test_gen, best_hyperparams, model_name=\"mobilenetv2_tuned\", image_size=(224, 224), epochs=20):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    \n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(image_size[0], image_size[1], 3), pooling='avg')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    params = best_hyperparams.values\n",
    "    dense_units_1 = params.get('units1')\n",
    "    dense_units_2 = params.get('units2')\n",
    "    dropout_1 = params.get('dropout1')\n",
    "    dropout_2 = params.get('dropout2')\n",
    "    learning_rate = params.get('learning_rate')\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(dense_units_1, activation='relu'),\n",
    "        Dropout(dropout_1),\n",
    "        Dense(dense_units_2, activation='relu'),\n",
    "        Dropout(dropout_2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    labels = train_generator.classes\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes ‚Äì Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    \n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix ‚Äì Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c46171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 2s/step - AUC: 0.5455 - accuracy: 0.0112 - loss: 5.6834 - val_AUC: 0.7572 - val_accuracy: 0.1130 - val_loss: 4.8308 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 172ms/step - AUC: 0.7193 - accuracy: 0.0785 - loss: 4.7089 - val_AUC: 0.8768 - val_accuracy: 0.2370 - val_loss: 4.0726 - learning_rate: 1.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - AUC: 0.8447 - accuracy: 0.1656 - loss: 3.9149 - val_AUC: 0.9227 - val_accuracy: 0.3318 - val_loss: 3.2261 - learning_rate: 1.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - AUC: 0.8948 - accuracy: 0.2575 - loss: 3.1822 - val_AUC: 0.9370 - val_accuracy: 0.3772 - val_loss: 2.7562 - learning_rate: 1.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - AUC: 0.9170 - accuracy: 0.3252 - loss: 2.6771 - val_AUC: 0.9422 - val_accuracy: 0.4136 - val_loss: 2.5109 - learning_rate: 1.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 175ms/step - AUC: 0.9335 - accuracy: 0.3673 - loss: 2.3265 - val_AUC: 0.9449 - val_accuracy: 0.4289 - val_loss: 2.3481 - learning_rate: 1.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - AUC: 0.9423 - accuracy: 0.4192 - loss: 2.0697 - val_AUC: 0.9467 - val_accuracy: 0.4520 - val_loss: 2.2246 - learning_rate: 1.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - AUC: 0.9524 - accuracy: 0.4632 - loss: 1.7894 - val_AUC: 0.9481 - val_accuracy: 0.4641 - val_loss: 2.1627 - learning_rate: 1.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - AUC: 0.9560 - accuracy: 0.4836 - loss: 1.6746 - val_AUC: 0.9484 - val_accuracy: 0.4788 - val_loss: 2.0900 - learning_rate: 1.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - AUC: 0.9599 - accuracy: 0.5158 - loss: 1.4916 - val_AUC: 0.9484 - val_accuracy: 0.4946 - val_loss: 2.0526 - learning_rate: 1.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - AUC: 0.9663 - accuracy: 0.5466 - loss: 1.4029 - val_AUC: 0.9484 - val_accuracy: 0.5019 - val_loss: 1.9942 - learning_rate: 1.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9693 - accuracy: 0.5707 - loss: 1.2657 - val_AUC: 0.9498 - val_accuracy: 0.5058 - val_loss: 1.9740 - learning_rate: 1.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9721 - accuracy: 0.6000 - loss: 1.1566 - val_AUC: 0.9499 - val_accuracy: 0.5172 - val_loss: 1.9529 - learning_rate: 1.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9730 - accuracy: 0.5967 - loss: 1.1134 - val_AUC: 0.9505 - val_accuracy: 0.5263 - val_loss: 1.9199 - learning_rate: 1.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9784 - accuracy: 0.6211 - loss: 1.0033 - val_AUC: 0.9500 - val_accuracy: 0.5273 - val_loss: 1.8984 - learning_rate: 1.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9775 - accuracy: 0.6497 - loss: 0.9370 - val_AUC: 0.9492 - val_accuracy: 0.5196 - val_loss: 1.9211 - learning_rate: 1.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 172ms/step - AUC: 0.9804 - accuracy: 0.6649 - loss: 0.8597 - val_AUC: 0.9488 - val_accuracy: 0.5317 - val_loss: 1.8664 - learning_rate: 1.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - AUC: 0.9832 - accuracy: 0.6728 - loss: 0.8318 - val_AUC: 0.9486 - val_accuracy: 0.5333 - val_loss: 1.8710 - learning_rate: 1.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 171ms/step - AUC: 0.9820 - accuracy: 0.6788 - loss: 0.7645 - val_AUC: 0.9489 - val_accuracy: 0.5480 - val_loss: 1.8553 - learning_rate: 1.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - AUC: 0.9849 - accuracy: 0.6973 - loss: 0.7175 - val_AUC: 0.9476 - val_accuracy: 0.5485 - val_loss: 1.8470 - learning_rate: 1.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 173ms/step - AUC: 0.9881 - accuracy: 0.7158 - loss: 0.6537 - val_AUC: 0.9459 - val_accuracy: 0.5466 - val_loss: 1.8586 - learning_rate: 1.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - AUC: 0.9873 - accuracy: 0.7184 - loss: 0.6382 - val_AUC: 0.9461 - val_accuracy: 0.5503 - val_loss: 1.8448 - learning_rate: 1.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 172ms/step - AUC: 0.9884 - accuracy: 0.7369 - loss: 0.5834 - val_AUC: 0.9468 - val_accuracy: 0.5564 - val_loss: 1.8456 - learning_rate: 1.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 171ms/step - AUC: 0.9891 - accuracy: 0.7537 - loss: 0.5504 - val_AUC: 0.9451 - val_accuracy: 0.5489 - val_loss: 1.8528 - learning_rate: 1.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - AUC: 0.9913 - accuracy: 0.7613 - loss: 0.5248\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 172ms/step - AUC: 0.9913 - accuracy: 0.7612 - loss: 0.5248 - val_AUC: 0.9448 - val_accuracy: 0.5466 - val_loss: 1.8513 - learning_rate: 1.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - AUC: 0.9916 - accuracy: 0.7719 - loss: 0.4774 - val_AUC: 0.9457 - val_accuracy: 0.5555 - val_loss: 1.8357 - learning_rate: 5.0000e-05\n",
      "Epoch 27/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 179ms/step - AUC: 0.9911 - accuracy: 0.7863 - loss: 0.4629 - val_AUC: 0.9454 - val_accuracy: 0.5568 - val_loss: 1.8308 - learning_rate: 5.0000e-05\n",
      "Epoch 28/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - AUC: 0.9938 - accuracy: 0.7824 - loss: 0.4491 - val_AUC: 0.9447 - val_accuracy: 0.5606 - val_loss: 1.8326 - learning_rate: 5.0000e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - AUC: 0.9911 - accuracy: 0.7908 - loss: 0.4286 - val_AUC: 0.9439 - val_accuracy: 0.5645 - val_loss: 1.8341 - learning_rate: 5.0000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - AUC: 0.9924 - accuracy: 0.7924 - loss: 0.4135\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 179ms/step - AUC: 0.9924 - accuracy: 0.7924 - loss: 0.4135 - val_AUC: 0.9430 - val_accuracy: 0.5587 - val_loss: 1.8349 - learning_rate: 5.0000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 178ms/step - AUC: 0.9933 - accuracy: 0.7944 - loss: 0.3949 - val_AUC: 0.9429 - val_accuracy: 0.5652 - val_loss: 1.8325 - learning_rate: 2.5000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - AUC: 0.9931 - accuracy: 0.8011 - loss: 0.3922 - val_AUC: 0.9438 - val_accuracy: 0.5690 - val_loss: 1.8276 - learning_rate: 2.5000e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 176ms/step - AUC: 0.9940 - accuracy: 0.8013 - loss: 0.3832 - val_AUC: 0.9436 - val_accuracy: 0.5685 - val_loss: 1.8296 - learning_rate: 2.5000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 195ms/step - AUC: 0.9937 - accuracy: 0.8184 - loss: 0.3729 - val_AUC: 0.9448 - val_accuracy: 0.5704 - val_loss: 1.8216 - learning_rate: 2.5000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 196ms/step - AUC: 0.9947 - accuracy: 0.8108 - loss: 0.3655 - val_AUC: 0.9432 - val_accuracy: 0.5722 - val_loss: 1.8243 - learning_rate: 2.5000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 193ms/step - AUC: 0.9943 - accuracy: 0.8186 - loss: 0.3545 - val_AUC: 0.9426 - val_accuracy: 0.5666 - val_loss: 1.8275 - learning_rate: 2.5000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - AUC: 0.9942 - accuracy: 0.8210 - loss: 0.3537\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 202ms/step - AUC: 0.9942 - accuracy: 0.8209 - loss: 0.3538 - val_AUC: 0.9431 - val_accuracy: 0.5706 - val_loss: 1.8266 - learning_rate: 2.5000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 200ms/step - AUC: 0.9929 - accuracy: 0.8184 - loss: 0.3521 - val_AUC: 0.9429 - val_accuracy: 0.5734 - val_loss: 1.8205 - learning_rate: 1.2500e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 202ms/step - AUC: 0.9948 - accuracy: 0.8318 - loss: 0.3258 - val_AUC: 0.9422 - val_accuracy: 0.5734 - val_loss: 1.8190 - learning_rate: 1.2500e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 197ms/step - AUC: 0.9951 - accuracy: 0.8222 - loss: 0.3452 - val_AUC: 0.9431 - val_accuracy: 0.5785 - val_loss: 1.8222 - learning_rate: 1.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 39.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 137ms/step - AUC: 0.9425 - accuracy: 0.5793 - loss: 1.8190\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ MobileNetV2 Tuned ‚Äì Results Summary:\n",
      "\n",
      "üìÅ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\mobilenetv2_tuned.h5\n",
      "üìÑ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\mobilenetv2_tuned_training_log.csv\n",
      "üìä Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\mobilenetv2_tuned_classification_report.csv\n",
      "üßØ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_tuned_classification_report_heatmap_top20.png\n",
      "üìâ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_tuned_confusion_matrix.png\n",
      "üìà Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_tuned_accuracy_plot.png\n",
      "üìë Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\mobilenetv2_tuned_predictions.csv\n",
      "‚úÖ Final validation accuracy:   57.34%\n",
      "üéØ Final validation AUC:        0.9422\n"
     ]
    }
   ],
   "source": [
    "results_mobilenetv2_tuned = run_mobilenetv2_tuned_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    best_hyperparams=best_hyperparams,\n",
    "    model_name=\"mobilenetv2_tuned\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"üì¶ MobileNetV2 Tuned ‚Äì Results Summary:\\n\")\n",
    "print(f\"üìÅ Model saved at:              {results_mobilenetv2_tuned['model_path']}\")\n",
    "print(f\"üìÑ Training log:                {results_mobilenetv2_tuned['log_path']}\")\n",
    "print(f\"üìä Classification report (CSV): {results_mobilenetv2_tuned['report_path']}\")\n",
    "print(f\"üßØ Report heatmap (Top 20):     {results_mobilenetv2_tuned['heatmap_path']}\")\n",
    "print(f\"üìâ Confusion matrix (full):     {results_mobilenetv2_tuned['confusion_matrix']}\")\n",
    "print(f\"üìà Accuracy plot:               {results_mobilenetv2_tuned['accuracy_plot']}\")\n",
    "print(f\"üìë Predictions CSV:             {results_mobilenetv2_tuned['predictions_path']}\")\n",
    "print(f\"‚úÖ Final validation accuracy:   {results_mobilenetv2_tuned['val_accuracy']:.2%}\")\n",
    "print(f\"üéØ Final validation AUC:        {results_mobilenetv2_tuned['val_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa920d5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">‚öôÔ∏è Set Up Hyperparameter Ranges for EfficientNetB0</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1fb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_hyperparams.values\n",
    "dense_units_1 = params.get('units1')\n",
    "dense_units_2 = params.get('units2')\n",
    "dropout_1 = params.get('dropout1')\n",
    "dropout_2 = params.get('dropout2')\n",
    "learning_rate = params.get('learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c8fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_efficientnetb0_tuned_pipeline(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    test_gen,\n",
    "    model_name=\"efficientnetb0_tuned\",\n",
    "    image_size=(224, 224),\n",
    "    epochs=20,\n",
    "    units1=1024,\n",
    "    units2=256,\n",
    "    dropout1=0.4,\n",
    "    dropout2=0.2,\n",
    "    learning_rate=5e-4\n",
    "):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(image_size[0], image_size[1], 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(units1, activation='relu')(x)\n",
    "    x = Dropout(dropout1)(x)\n",
    "    x = Dense(units2, activation='relu')(x)\n",
    "    x = Dropout(dropout2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", AUC(name=\"AUC\")]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    labels = train_generator.classes\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes ‚Äì Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix ‚Äì Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1ae86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - AUC: 0.5433 - accuracy: 0.0093 - loss: 5.2314 - val_AUC: 0.5578 - val_accuracy: 0.0135 - val_loss: 5.2680 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - AUC: 0.7178 - accuracy: 0.0760 - loss: 4.8634 - val_AUC: 0.6192 - val_accuracy: 0.0459 - val_loss: 5.0852 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 989ms/step - AUC: 0.8686 - accuracy: 0.1827 - loss: 3.8577 - val_AUC: 0.9232 - val_accuracy: 0.2894 - val_loss: 3.2731 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - AUC: 0.9246 - accuracy: 0.2927 - loss: 2.8530 - val_AUC: 0.8802 - val_accuracy: 0.2409 - val_loss: 3.5035 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 902ms/step - AUC: 0.9481 - accuracy: 0.3680 - loss: 2.2843 - val_AUC: 0.8444 - val_accuracy: 0.1973 - val_loss: 3.8251 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827ms/step - AUC: 0.9590 - accuracy: 0.4538 - loss: 1.8887\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 909ms/step - AUC: 0.9590 - accuracy: 0.4538 - loss: 1.8885 - val_AUC: 0.8519 - val_accuracy: 0.2190 - val_loss: 3.6575 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 961ms/step - AUC: 0.9711 - accuracy: 0.5167 - loss: 1.5163 - val_AUC: 0.9382 - val_accuracy: 0.4031 - val_loss: 2.4725 - learning_rate: 5.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 970ms/step - AUC: 0.9740 - accuracy: 0.5466 - loss: 1.3261 - val_AUC: 0.9443 - val_accuracy: 0.4380 - val_loss: 2.2941 - learning_rate: 5.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 984ms/step - AUC: 0.9774 - accuracy: 0.5720 - loss: 1.2168 - val_AUC: 0.9519 - val_accuracy: 0.4928 - val_loss: 2.0329 - learning_rate: 5.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 933ms/step - AUC: 0.9816 - accuracy: 0.6028 - loss: 1.1140 - val_AUC: 0.9486 - val_accuracy: 0.4844 - val_loss: 2.0995 - learning_rate: 5.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 928ms/step - AUC: 0.9835 - accuracy: 0.6393 - loss: 0.9673 - val_AUC: 0.9404 - val_accuracy: 0.4543 - val_loss: 2.2398 - learning_rate: 5.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 929ms/step - AUC: 0.9857 - accuracy: 0.6429 - loss: 0.8876 - val_AUC: 0.9475 - val_accuracy: 0.5103 - val_loss: 2.0137 - learning_rate: 5.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 931ms/step - AUC: 0.9861 - accuracy: 0.6716 - loss: 0.8102 - val_AUC: 0.9493 - val_accuracy: 0.5396 - val_loss: 1.9276 - learning_rate: 5.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 926ms/step - AUC: 0.9870 - accuracy: 0.6935 - loss: 0.7529 - val_AUC: 0.9528 - val_accuracy: 0.5524 - val_loss: 1.8159 - learning_rate: 5.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - AUC: 0.9905 - accuracy: 0.7192 - loss: 0.6604 - val_AUC: 0.9435 - val_accuracy: 0.5415 - val_loss: 1.9281 - learning_rate: 5.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 996ms/step - AUC: 0.9912 - accuracy: 0.7361 - loss: 0.6335 - val_AUC: 0.9471 - val_accuracy: 0.5457 - val_loss: 1.9000 - learning_rate: 5.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837ms/step - AUC: 0.9920 - accuracy: 0.7504 - loss: 0.5588\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 921ms/step - AUC: 0.9920 - accuracy: 0.7504 - loss: 0.5588 - val_AUC: 0.9263 - val_accuracy: 0.4511 - val_loss: 2.3838 - learning_rate: 5.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 914ms/step - AUC: 0.9921 - accuracy: 0.7613 - loss: 0.5220 - val_AUC: 0.9508 - val_accuracy: 0.5853 - val_loss: 1.7059 - learning_rate: 2.5000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - AUC: 0.9923 - accuracy: 0.7817 - loss: 0.4856 - val_AUC: 0.9528 - val_accuracy: 0.5843 - val_loss: 1.7198 - learning_rate: 2.5000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - AUC: 0.9928 - accuracy: 0.7764 - loss: 0.4669 - val_AUC: 0.5544 - val_accuracy: 0.0249 - val_loss: 5.7092 - learning_rate: 2.5000e-05\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 235ms/step - AUC: 0.9511 - accuracy: 0.5699 - loss: 1.7408\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 732ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ EfficientNetB0 (Tuned w/ Best Hyperparams) ‚Äì Results Summary:\n",
      "\n",
      "üìÅ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\efficientnetb0_best.h5\n",
      "üìÑ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\efficientnetb0_best_training_log.csv\n",
      "üìä Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\efficientnetb0_best_classification_report.csv\n",
      "üßØ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_best_classification_report_heatmap_top20.png\n",
      "üìâ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_best_confusion_matrix.png\n",
      "üìà Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_best_accuracy_plot.png\n",
      "üìë Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\efficientnetb0_best_predictions.csv\n",
      "‚úÖ Final validation accuracy:   58,53%\n",
      "üéØ Final validation AUC:        95,08%\n"
     ]
    }
   ],
   "source": [
    "results_efficientnetb0_tuned = run_efficientnetb0_tuned_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"efficientnetb0_best\",\n",
    "    epochs=20,\n",
    "    units1=dense_units_1,\n",
    "    units2=dense_units_2,\n",
    "    dropout1=dropout_1,\n",
    "    dropout2=dropout_2,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_efficientnetb0_tuned['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_efficientnetb0_tuned['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"\\nüì¶ EfficientNetB0 (Tuned w/ Best Hyperparams) ‚Äì Results Summary:\\n\")\n",
    "print(f\"üìÅ Model saved at:              {results_efficientnetb0_tuned['model_path']}\")\n",
    "print(f\"üìÑ Training log:                {results_efficientnetb0_tuned['log_path']}\")\n",
    "print(f\"üìä Classification report (CSV): {results_efficientnetb0_tuned['report_path']}\")\n",
    "print(f\"üßØ Report heatmap (Top 20):     {results_efficientnetb0_tuned['heatmap_path']}\")\n",
    "print(f\"üìâ Confusion matrix (full):     {results_efficientnetb0_tuned['confusion_matrix']}\")\n",
    "print(f\"üìà Accuracy plot:               {results_efficientnetb0_tuned['accuracy_plot']}\")\n",
    "print(f\"üìë Predictions CSV:             {results_efficientnetb0_tuned['predictions_path']}\")\n",
    "print(f\"‚úÖ Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"üéØ Final validation AUC:        {val_auc_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
