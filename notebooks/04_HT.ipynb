{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057bbc14",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #FF8C42; padding:20px; border-radius:10px; font-family:Arial, sans-serif; text-align:center; font-size:28px; font-weight:bold;\">\n",
    "  ‚öôÔ∏è 04 ‚Äì Hyperparameter Tuning\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600257f8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üì¶ Import Libraries and Define Paths</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p style=\"font-size:18px;\">This is the initial block of the rare species image classification project.</p>\n",
    "\n",
    "  <p>In this section, we perform the following tasks:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li>üìÅ <strong>Import libraries</strong> for data manipulation (<code>pandas</code>), file paths (<code>pathlib</code>), and image processing (<code>PIL</code>).</li>\n",
    "    <li>üñºÔ∏è <strong>Apply visual styling</strong> using <code>matplotlib</code> and <code>seaborn</code> to ensure clean and consistent plots.</li>\n",
    "    <li>üìÇ <strong>Define the main project directories</strong>, including image folders and the metadata CSV file.</li>\n",
    "    <li>‚úÖ <strong>Automatic path validation</strong> to ensure all required files and directories exist.</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>This setup provides a reliable foundation for safely loading and exploring the dataset.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82830fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193efc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'output'\n",
    "LOGS_DIR = OUTPUTS_DIR / 'logs'\n",
    "PREDICTIONS_DIR = OUTPUTS_DIR / 'predictions'\n",
    "TRAIN_DIR = PROCESSED_DIR / 'train'\n",
    "VAL_DIR = PROCESSED_DIR / 'val'\n",
    "TEST_DIR = PROCESSED_DIR / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034564d4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üì¶ Define Parameters</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p>In this section, we define the core parameters that will guide the training process of the model. These include the input image size, batch size, number of training epochs, and the directory structure of the dataset.</p>\n",
    "  \n",
    "  <p>Setting these values early ensures consistency across all steps and allows for easier adjustments when experimenting with different model architectures or datasets.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dafeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eae14d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üìÇ Load and Prepare the Dataset</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "  <p>This section is responsible for loading the processed dataset and preparing it for training and evaluation.</p>\n",
    "\n",
    "  <p>Using <code>ImageDataGenerator</code>, the images are normalized (pixel values scaled between 0 and 1), and loaded in batches directly from the respective folders for:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li><strong>üü¢ Training set</strong> ‚Äî used to update model weights during learning</li>\n",
    "    <li><strong>üü† Validation set</strong> ‚Äî used to monitor generalization and prevent overfitting</li>\n",
    "    <li><strong>üîµ Test set</strong> ‚Äî used for final evaluation after training</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>The dataset is expected to be organized in subfolders where each folder represents one class label.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae733941",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_generator = datagen.flow_from_directory(VAL_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_generator = datagen.flow_from_directory(TEST_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "NUM_CLASSES = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9daea",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">üìÇ Balance Weights</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.classes\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28d9fa",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">‚öôÔ∏è Set Up Hyperparameter Ranges for MobileNetV2</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenetv2(hp):\n",
    "    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(hp.Int('units1', min_value=128, max_value=1024, step=64), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout1', 0.3, 0.6, step=0.1)))\n",
    "\n",
    "    model.add(Dense(hp.Int('units2', min_value=64, max_value=512, step=64), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout2', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    lr = hp.Choice('learning_rate', [1e-2, 1e-3, 5e-4, 1e-4])\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413060f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_mobilenetv2,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=EPOCHS,\n",
    "    factor=3,\n",
    "    directory= LOGS_DIR / 'tuner_logs',\n",
    "    project_name='mobilenetv2_tuning'\n",
    ")\n",
    "\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb394b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparams = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Melhores hiperpar√¢metros encontrados:\")\n",
    "print(best_hyperparams.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87352770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mobilenetv2_tuned_pipeline(train_gen, val_gen, test_gen, best_hyperparams, model_name=\"mobilenetv2_tuned\", image_size=(224, 224), epochs=20):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    \n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(image_size[0], image_size[1], 3), pooling='avg')\n",
    "    base_model.trainable = False\n",
    "\n",
    "    dense_units_1 = best_hyperparams.get('dense_units_1')\n",
    "    dense_units_2 = best_hyperparams.get('dense_units_2')\n",
    "    dropout_1 = best_hyperparams.get('dropout_1')\n",
    "    dropout_2 = best_hyperparams.get('dropout_2')\n",
    "    learning_rate = best_hyperparams.get('learning_rate')\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(dense_units_1, activation='relu'),\n",
    "        Dropout(dropout_1),\n",
    "        Dense(dense_units_2, activation='relu'),\n",
    "        Dropout(dropout_2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    labels = train_generator.classes\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes ‚Äì Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    \n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix ‚Äì Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c46171",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mobilenetv2_tuned = run_mobilenetv2_tuned_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    best_hyperparams=best_hyperparams,\n",
    "    model_name=\"mobilenetv2_tuned\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "print(\"üì¶ MobileNetV2 Tuned ‚Äì Results Summary:\\n\")\n",
    "print(f\"üìÅ Model saved at:              {results_mobilenetv2_tuned['model_path']}\")\n",
    "print(f\"üìÑ Training log:                {results_mobilenetv2_tuned['log_path']}\")\n",
    "print(f\"üìä Classification report (CSV): {results_mobilenetv2_tuned['report_path']}\")\n",
    "print(f\"üßØ Report heatmap (Top 20):     {results_mobilenetv2_tuned['heatmap_path']}\")\n",
    "print(f\"üìâ Confusion matrix (full):     {results_mobilenetv2_tuned['confusion_matrix']}\")\n",
    "print(f\"üìà Accuracy plot:               {results_mobilenetv2_tuned['accuracy_plot']}\")\n",
    "print(f\"üìë Predictions CSV:             {results_mobilenetv2_tuned['predictions_path']}\")\n",
    "print(f\"‚úÖ Final validation accuracy:   {results_mobilenetv2_tuned['val_accuracy']:.2%}\")\n",
    "print(f\"üéØ Final validation AUC:        {results_mobilenetv2_tuned['val_auc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa920d5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">‚öôÔ∏è Set Up Hyperparameter Ranges for EfficientNetB0</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnetb0(hp):\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(\n",
    "        units=hp.Int('units1', min_value=128, max_value=1024, step=64),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = Dropout(\n",
    "        rate=hp.Float('dropout1', min_value=0.3, max_value=0.6, step=0.1)\n",
    "    )(x)\n",
    "\n",
    "    x = Dense(\n",
    "        units=hp.Int('units2', min_value=64, max_value=512, step=64),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = Dropout(\n",
    "        rate=hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    )(x)\n",
    "\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 5e-4, 1e-4])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='AUC')]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_efficientnetb0,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=EPOCHS,\n",
    "    factor=3,\n",
    "    directory= LOGS_DIR / 'tuner_logs_eff',\n",
    "    project_name='efficientnetB0_tuning'\n",
    ")\n",
    "\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=[stop_early],class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparams = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Best hyperparams found:\")\n",
    "print(best_hyperparams.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = best_hyperparams.get('units1')\n",
    "units2 = best_hyperparams.get('units2')\n",
    "dropout1 = best_hyperparams.get('dropout1')\n",
    "dropout2 = best_hyperparams.get('dropout2')\n",
    "learning_rate = best_hyperparams.get('learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_efficientnetb0_tuned_pipeline(\n",
    "    train_gen,\n",
    "    val_gen,\n",
    "    test_gen,\n",
    "    model_name=\"efficientnetb0_tuned\",\n",
    "    image_size=(224, 224),\n",
    "    epochs=20,\n",
    "    units1=1024,\n",
    "    units2=256,\n",
    "    dropout1=0.4,\n",
    "    dropout2=0.2,\n",
    "    learning_rate=5e-4\n",
    "):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(image_size[0], image_size[1], 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(units1, activation='relu'),\n",
    "        Dropout(dropout1),\n",
    "        Dense(units2, activation='relu'),\n",
    "        Dropout(dropout2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes ‚Äì Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix ‚Äì Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ae86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_efficientnetb0_tuned = run_efficientnetb0_tuned_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"efficientnetb0_best\",\n",
    "    epochs=20,\n",
    "    units1=units1,\n",
    "    units2=units2,\n",
    "    dropout1=dropout1,\n",
    "    dropout2=dropout2,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_efficientnetb0_tuned['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_efficientnetb0_tuned['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"\\nüì¶ EfficientNetB0 (Tuned w/ Best Hyperparams) ‚Äì Results Summary:\\n\")\n",
    "print(f\"üìÅ Model saved at:              {results_efficientnetb0_tuned['model_path']}\")\n",
    "print(f\"üìÑ Training log:                {results_efficientnetb0_tuned['log_path']}\")\n",
    "print(f\"üìä Classification report (CSV): {results_efficientnetb0_tuned['report_path']}\")\n",
    "print(f\"üßØ Report heatmap (Top 20):     {results_efficientnetb0_tuned['heatmap_path']}\")\n",
    "print(f\"üìâ Confusion matrix (full):     {results_efficientnetb0_tuned['confusion_matrix']}\")\n",
    "print(f\"üìà Accuracy plot:               {results_efficientnetb0_tuned['accuracy_plot']}\")\n",
    "print(f\"üìë Predictions CSV:             {results_efficientnetb0_tuned['predictions_path']}\")\n",
    "print(f\"‚úÖ Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"üéØ Final validation AUC:        {val_auc_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
