{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75201c6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #00A86B; padding:20px; border-radius:10px; font-family:Arial, sans-serif; text-align:center; font-size:28px; font-weight:bold;\">\n",
    "  ğŸ” 03 â€“ Transfer Learning and Model Selection\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9096cfa8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Import Libraries and Define Paths</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p style=\"font-size:18px;\">This is the initial block of the rare species image classification project.</p>\n",
    "\n",
    "  <p>In this section, we perform the following tasks:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li>ğŸ“ <strong>Import libraries</strong> for data manipulation (<code>pandas</code>), file paths (<code>pathlib</code>), and image processing (<code>PIL</code>).</li>\n",
    "    <li>ğŸ–¼ï¸ <strong>Apply visual styling</strong> using <code>matplotlib</code> and <code>seaborn</code> to ensure clean and consistent plots.</li>\n",
    "    <li>ğŸ“‚ <strong>Define the main project directories</strong>, including image folders and the metadata CSV file.</li>\n",
    "    <li>âœ… <strong>Automatic path validation</strong> to ensure all required files and directories exist.</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>This setup provides a reliable foundation for safely loading and exploring the dataset.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec53ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50, InceptionV3, DenseNet121, MobileNetV2, VGG16, ConvNeXtBase\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726c80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path().resolve().parent\n",
    "\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'output'\n",
    "LOGS_DIR = OUTPUTS_DIR / 'logs'\n",
    "PREDICTIONS_DIR = OUTPUTS_DIR / 'predictions'\n",
    "TRAIN_DIR = PROCESSED_DIR / 'train'\n",
    "VAL_DIR = PROCESSED_DIR / 'val'\n",
    "TEST_DIR = PROCESSED_DIR / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef1a3f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Define Parameters</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  <p>In this section, we define the core parameters that will guide the training process of the model. These include the input image size, batch size, number of training epochs, and the directory structure of the dataset.</p>\n",
    "  \n",
    "  <p>Setting these values early ensures consistency across all steps and allows for easier adjustments when experimenting with different model architectures or datasets.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b04ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "EPOCHS_EFFECIENT = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702e9c3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“‚ Load and Prepare the Dataset</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "  <p>This section is responsible for loading the processed dataset and preparing it for training and evaluation.</p>\n",
    "\n",
    "  <p>Using <code>ImageDataGenerator</code>, the images are normalized (pixel values scaled between 0 and 1), and loaded in batches directly from the respective folders for:</p>\n",
    "\n",
    "  <ul style=\"line-height: 1.6;\">\n",
    "    <li><strong>ğŸŸ¢ Training set</strong> â€” used to update model weights during learning</li>\n",
    "    <li><strong>ğŸŸ  Validation set</strong> â€” used to monitor generalization and prevent overfitting</li>\n",
    "    <li><strong>ğŸ”µ Test set</strong> â€” used for final evaluation after training</li>\n",
    "  </ul>\n",
    "\n",
    "  <p>The dataset is expected to be organized in subfolders where each folder represents one class label.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f16297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8462 images belonging to 202 classes.\n",
      "Found 4292 images belonging to 202 classes.\n",
      "Found 1199 images belonging to 202 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_generator = datagen.flow_from_directory(VAL_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_generator = datagen.flow_from_directory(TEST_DIR, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "NUM_CLASSES = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7f696",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“‚ Balance Weights</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px; font-family:Arial, sans-serif; font-size:16px;\"> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f267135",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.classes\n",
    "class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d2dc3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Baseline EfficientNetB0 Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0447ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_efficientnetb0_pipeline(train_gen, val_gen, test_gen, model_name=\"efficientnetb0_baseline\", epochs=EPOCHS_EFFECIENT):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True \n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8761dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - AUC: 0.5460 - accuracy: 0.0110 - loss: 5.2710 - val_AUC: 0.5463 - val_accuracy: 0.0070 - val_loss: 5.2898 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 863ms/step - AUC: 0.7226 - accuracy: 0.0651 - loss: 4.9062 - val_AUC: 0.7128 - val_accuracy: 0.0869 - val_loss: 4.8113 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 878ms/step - AUC: 0.8535 - accuracy: 0.1715 - loss: 3.9739 - val_AUC: 0.7693 - val_accuracy: 0.1216 - val_loss: 4.5959 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 875ms/step - AUC: 0.9189 - accuracy: 0.2784 - loss: 3.0547 - val_AUC: 0.8233 - val_accuracy: 0.1754 - val_loss: 4.0196 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 876ms/step - AUC: 0.9422 - accuracy: 0.3567 - loss: 2.4197 - val_AUC: 0.8398 - val_accuracy: 0.1918 - val_loss: 3.8128 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 881ms/step - AUC: 0.9610 - accuracy: 0.4566 - loss: 1.8951 - val_AUC: 0.8929 - val_accuracy: 0.2801 - val_loss: 3.2502 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 876ms/step - AUC: 0.9684 - accuracy: 0.4968 - loss: 1.6175 - val_AUC: 0.8860 - val_accuracy: 0.2740 - val_loss: 3.2969 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 879ms/step - AUC: 0.9734 - accuracy: 0.5434 - loss: 1.3651 - val_AUC: 0.8785 - val_accuracy: 0.2936 - val_loss: 3.2603 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 879ms/step - AUC: 0.9810 - accuracy: 0.5945 - loss: 1.1334 - val_AUC: 0.9001 - val_accuracy: 0.3597 - val_loss: 2.8838 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 881ms/step - AUC: 0.9833 - accuracy: 0.6479 - loss: 0.9349 - val_AUC: 0.9324 - val_accuracy: 0.4699 - val_loss: 2.2408 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 893ms/step - AUC: 0.9873 - accuracy: 0.6806 - loss: 0.8220 - val_AUC: 0.9360 - val_accuracy: 0.4699 - val_loss: 2.1845 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 887ms/step - AUC: 0.9904 - accuracy: 0.7106 - loss: 0.6807 - val_AUC: 0.8819 - val_accuracy: 0.3034 - val_loss: 3.1729 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 896ms/step - AUC: 0.9904 - accuracy: 0.7292 - loss: 0.6311 - val_AUC: 0.8264 - val_accuracy: 0.2542 - val_loss: 3.7686 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811ms/step - AUC: 0.9927 - accuracy: 0.7598 - loss: 0.5288\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 892ms/step - AUC: 0.9927 - accuracy: 0.7598 - loss: 0.5289 - val_AUC: 0.9090 - val_accuracy: 0.4210 - val_loss: 2.6075 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 899ms/step - AUC: 0.9927 - accuracy: 0.7945 - loss: 0.4482 - val_AUC: 0.9487 - val_accuracy: 0.5624 - val_loss: 1.7690 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 896ms/step - AUC: 0.9940 - accuracy: 0.8088 - loss: 0.4143 - val_AUC: 0.9286 - val_accuracy: 0.5116 - val_loss: 2.1303 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 894ms/step - AUC: 0.6160 - accuracy: 0.1659 - loss: 4.4283 - val_AUC: 0.5330 - val_accuracy: 0.0177 - val_loss: 5.3055 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812ms/step - AUC: 0.5321 - accuracy: 0.0173 - loss: 5.3582\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 892ms/step - AUC: 0.5321 - accuracy: 0.0173 - loss: 5.3580 - val_AUC: 0.5330 - val_accuracy: 0.0177 - val_loss: 5.3055 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 886ms/step - AUC: 0.5350 - accuracy: 0.0201 - loss: 5.2785 - val_AUC: 0.5330 - val_accuracy: 0.0177 - val_loss: 5.3055 - learning_rate: 2.5000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 885ms/step - AUC: 0.5334 - accuracy: 0.0190 - loss: 5.3371 - val_AUC: 0.5330 - val_accuracy: 0.0177 - val_loss: 5.3055 - learning_rate: 2.5000e-05\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 170ms/step - AUC: 0.9491 - accuracy: 0.5717 - loss: 1.7511\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results_efficientnetb0 = run_efficientnetb0_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"efficientnetb0_baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed6c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ EfficientNetB0 â€“ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\efficientnetb0_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\efficientnetb0_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\efficientnetb0_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‰ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_baseline_confusion_matrix.png\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\efficientnetb0_baseline_accuracy_plot.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\efficientnetb0_baseline_predictions.csv\n",
      "âœ… Final validation accuracy:   56,24%\n"
     ]
    }
   ],
   "source": [
    "val_accuracy_str = f\"{results_efficientnetb0['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"ğŸ“¦ EfficientNetB0 â€“ Results Summary:\\n\")\n",
    "print(f\"ğŸ“ Model saved at:              {results_efficientnetb0['model_path']}\")\n",
    "print(f\"ğŸ“„ Training log:                {results_efficientnetb0['log_path']}\")\n",
    "print(f\"ğŸ“Š Classification report (CSV): {results_efficientnetb0['report_path']}\")\n",
    "print(f\"ğŸ§¯ Report heatmap (Top 20):     {results_efficientnetb0['heatmap_path']}\")\n",
    "print(f\"ğŸ“‰ Confusion matrix (full):     {results_efficientnetb0['confusion_matrix']}\")\n",
    "print(f\"ğŸ“ˆ Accuracy plot:               {results_efficientnetb0['accuracy_plot']}\")\n",
    "print(f\"ğŸ“‘ Predictions CSV:             {results_efficientnetb0['predictions_path']}\")\n",
    "print(f\"âœ… Final validation accuracy:   {val_accuracy_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c646f6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Baseline ResNet50 Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "163eac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_resnet50_pipeline(train_gen, val_gen, test_gen, model_name=\"resnet50_baseline\", image_size=IMAGE_SIZE, epochs=EPOCHS_EFFECIENT):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=5e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8d5bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 638ms/step - AUC: 0.5565 - accuracy: 0.0103 - loss: 5.4509 - val_AUC: 0.6250 - val_accuracy: 0.0366 - val_loss: 5.1860 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 575ms/step - AUC: 0.6493 - accuracy: 0.0336 - loss: 5.0106 - val_AUC: 0.6725 - val_accuracy: 0.0499 - val_loss: 4.9729 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 602ms/step - AUC: 0.6845 - accuracy: 0.0434 - loss: 4.8823 - val_AUC: 0.6940 - val_accuracy: 0.0596 - val_loss: 4.8717 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 604ms/step - AUC: 0.7129 - accuracy: 0.0548 - loss: 4.7589 - val_AUC: 0.7092 - val_accuracy: 0.0650 - val_loss: 4.8336 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 584ms/step - AUC: 0.7360 - accuracy: 0.0745 - loss: 4.4484 - val_AUC: 0.7230 - val_accuracy: 0.0643 - val_loss: 4.7656 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 581ms/step - AUC: 0.7570 - accuracy: 0.0797 - loss: 4.3528 - val_AUC: 0.7329 - val_accuracy: 0.0727 - val_loss: 89963.3047 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 579ms/step - AUC: 0.7679 - accuracy: 0.0881 - loss: 4.2157 - val_AUC: 0.7373 - val_accuracy: 0.0799 - val_loss: 4.6815 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 580ms/step - AUC: 0.7825 - accuracy: 0.1036 - loss: 4.1746 - val_AUC: 0.7477 - val_accuracy: 0.0867 - val_loss: 4.6540 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 580ms/step - AUC: 0.7962 - accuracy: 0.1269 - loss: 4.0346 - val_AUC: 0.7549 - val_accuracy: 0.0832 - val_loss: 4.6554 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 579ms/step - AUC: 0.8063 - accuracy: 0.1238 - loss: 3.8899 - val_AUC: 0.7585 - val_accuracy: 0.0916 - val_loss: 4.6267 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 580ms/step - AUC: 0.8189 - accuracy: 0.1388 - loss: 3.7551 - val_AUC: 0.7562 - val_accuracy: 0.0897 - val_loss: 4.6360 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 583ms/step - AUC: 0.8345 - accuracy: 0.1527 - loss: 3.6652 - val_AUC: 0.7538 - val_accuracy: 0.0955 - val_loss: 4.6706 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - AUC: 0.8386 - accuracy: 0.1674 - loss: 3.5010\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 585ms/step - AUC: 0.8386 - accuracy: 0.1673 - loss: 3.5013 - val_AUC: 0.7524 - val_accuracy: 0.1025 - val_loss: 4.6714 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 583ms/step - AUC: 0.8538 - accuracy: 0.1845 - loss: 3.3764 - val_AUC: 0.7529 - val_accuracy: 0.1002 - val_loss: 4.6949 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 583ms/step - AUC: 0.8641 - accuracy: 0.2022 - loss: 3.2174 - val_AUC: 0.7598 - val_accuracy: 0.1053 - val_loss: 4.6856 - learning_rate: 2.5000e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 391ms/step - AUC: 0.7615 - accuracy: 0.0969 - loss: 4.6065\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ResNet50 â€“ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\resnet50_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\resnet50_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\resnet50_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\resnet50_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‰ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\resnet50_baseline_confusion_matrix.png\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\resnet50_baseline_accuracy_plot.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\resnet50_baseline_predictions.csv\n",
      "âœ… Final validation accuracy:   9,16%\n",
      "ğŸ¯ Final validation AUC:        75,85%\n"
     ]
    }
   ],
   "source": [
    "results_resnet50 = run_resnet50_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_resnet50['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_resnet50['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"ğŸ“¦ ResNet50 â€“ Results Summary:\\n\")\n",
    "print(f\"ğŸ“ Model saved at:              {results_resnet50['model_path']}\")\n",
    "print(f\"ğŸ“„ Training log:                {results_resnet50['log_path']}\")\n",
    "print(f\"ğŸ“Š Classification report (CSV): {results_resnet50['report_path']}\")\n",
    "print(f\"ğŸ§¯ Report heatmap (Top 20):     {results_resnet50['heatmap_path']}\")\n",
    "print(f\"ğŸ“‰ Confusion matrix (full):     {results_resnet50['confusion_matrix']}\")\n",
    "print(f\"ğŸ“ˆ Accuracy plot:               {results_resnet50['accuracy_plot']}\")\n",
    "print(f\"ğŸ“‘ Predictions CSV:             {results_resnet50['predictions_path']}\")\n",
    "print(f\"âœ… Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"ğŸ¯ Final validation AUC:        {val_auc_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ff4e6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Baseline DenseNet121 Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c1e2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_densenet121_pipeline(train_gen, val_gen, test_gen, model_name=\"densenet121_baseline\", image_size=IMAGE_SIZE, epochs=EPOCHS_EFFECIENT):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = DenseNet121(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=5e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7373611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 611ms/step - AUC: 0.6093 - accuracy: 0.0247 - loss: 5.3303 - val_AUC: 0.6213 - val_accuracy: 0.0298 - val_loss: 365049658342472654852626317312.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 588ms/step - AUC: 0.8685 - accuracy: 0.1776 - loss: 3.6993 - val_AUC: 0.6851 - val_accuracy: 0.0345 - val_loss: 5.1690 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 590ms/step - AUC: 0.9229 - accuracy: 0.3021 - loss: 2.7063 - val_AUC: 0.6711 - val_accuracy: 0.0359 - val_loss: 5.1946 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 589ms/step - AUC: 0.9392 - accuracy: 0.3590 - loss: 2.3166 - val_AUC: 0.6769 - val_accuracy: 0.0336 - val_loss: 5.1912 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - AUC: 0.9486 - accuracy: 0.4249 - loss: 1.9445\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 587ms/step - AUC: 0.9486 - accuracy: 0.4249 - loss: 1.9445 - val_AUC: 0.6740 - val_accuracy: 0.0319 - val_loss: 5.2004 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 588ms/step - AUC: 0.9586 - accuracy: 0.4682 - loss: 1.6605 - val_AUC: 0.6709 - val_accuracy: 0.0312 - val_loss: 5.1987 - learning_rate: 2.5000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 585ms/step - AUC: 0.9626 - accuracy: 0.5004 - loss: 1.5460 - val_AUC: 0.5693 - val_accuracy: 0.0184 - val_loss: 166266193607364425920079200256.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 399ms/step - AUC: 0.6820 - accuracy: 0.0347 - loss: 5.1696\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 844ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ DenseNet121 â€“ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\densenet121_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\densenet121_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\densenet121_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\densenet121_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‰ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\densenet121_baseline_confusion_matrix.png\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\densenet121_baseline_accuracy_plot.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\densenet121_baseline_predictions.csv\n",
      "âœ… Final validation accuracy:   3,45%\n",
      "ğŸ¯ Final validation AUC:        68,51%\n"
     ]
    }
   ],
   "source": [
    "results_densenet121 = run_densenet121_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"densenet121_baseline\"\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_densenet121['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_densenet121['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"ğŸ“¦ DenseNet121 â€“ Results Summary:\\n\")\n",
    "print(f\"ğŸ“ Model saved at:              {results_densenet121['model_path']}\")\n",
    "print(f\"ğŸ“„ Training log:                {results_densenet121['log_path']}\")\n",
    "print(f\"ğŸ“Š Classification report (CSV): {results_densenet121['report_path']}\")\n",
    "print(f\"ğŸ§¯ Report heatmap (Top 20):     {results_densenet121['heatmap_path']}\")\n",
    "print(f\"ğŸ“‰ Confusion matrix (full):     {results_densenet121['confusion_matrix']}\")\n",
    "print(f\"ğŸ“ˆ Accuracy plot:               {results_densenet121['accuracy_plot']}\")\n",
    "print(f\"ğŸ“‘ Predictions CSV:             {results_densenet121['predictions_path']}\")\n",
    "print(f\"âœ… Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"ğŸ¯ Final validation AUC:        {val_auc_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d1bb9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Baseline MobileNetV2 Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24a5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mobilenetv2_pipeline(train_gen, val_gen, test_gen, model_name=\"mobilenetv2_baseline\", image_size=IMAGE_SIZE, epochs=EPOCHS_EFFECIENT):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=5e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f015004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 182ms/step - AUC: 0.6023 - accuracy: 0.0263 - loss: 5.4021 - val_AUC: 0.8846 - val_accuracy: 0.2307 - val_loss: 3.8933 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - AUC: 0.8543 - accuracy: 0.1782 - loss: 3.6748 - val_AUC: 0.9347 - val_accuracy: 0.3320 - val_loss: 2.7963 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - AUC: 0.9088 - accuracy: 0.2998 - loss: 2.7213 - val_AUC: 0.9389 - val_accuracy: 0.3968 - val_loss: 2.4816 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 177ms/step - AUC: 0.9293 - accuracy: 0.3614 - loss: 2.2664 - val_AUC: 0.9422 - val_accuracy: 0.4061 - val_loss: 2.3631 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 178ms/step - AUC: 0.9451 - accuracy: 0.4170 - loss: 1.9290 - val_AUC: 0.9449 - val_accuracy: 0.4432 - val_loss: 2.2111 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 179ms/step - AUC: 0.9536 - accuracy: 0.4732 - loss: 1.6350 - val_AUC: 0.9464 - val_accuracy: 0.4553 - val_loss: 2.1544 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 181ms/step - AUC: 0.9557 - accuracy: 0.5037 - loss: 1.5093 - val_AUC: 0.9474 - val_accuracy: 0.4795 - val_loss: 2.0616 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 179ms/step - AUC: 0.9656 - accuracy: 0.5215 - loss: 1.3276 - val_AUC: 0.9443 - val_accuracy: 0.4767 - val_loss: 2.1060 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 180ms/step - AUC: 0.9667 - accuracy: 0.5625 - loss: 1.2088 - val_AUC: 0.9407 - val_accuracy: 0.4795 - val_loss: 2.0921 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - AUC: 0.9714 - accuracy: 0.5844 - loss: 1.0689\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 180ms/step - AUC: 0.9714 - accuracy: 0.5844 - loss: 1.0691 - val_AUC: 0.9428 - val_accuracy: 0.4972 - val_loss: 2.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 182ms/step - AUC: 0.9738 - accuracy: 0.6194 - loss: 1.0023 - val_AUC: 0.9440 - val_accuracy: 0.5049 - val_loss: 1.9980 - learning_rate: 2.5000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 183ms/step - AUC: 0.9811 - accuracy: 0.6445 - loss: 0.8417 - val_AUC: 0.9439 - val_accuracy: 0.5126 - val_loss: 2.0051 - learning_rate: 2.5000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 186ms/step - AUC: 0.9804 - accuracy: 0.6623 - loss: 0.8099 - val_AUC: 0.9412 - val_accuracy: 0.5161 - val_loss: 2.0025 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - AUC: 0.9814 - accuracy: 0.6605 - loss: 0.7783\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 186ms/step - AUC: 0.9814 - accuracy: 0.6606 - loss: 0.7783 - val_AUC: 0.9419 - val_accuracy: 0.5130 - val_loss: 2.0132 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - AUC: 0.9841 - accuracy: 0.6918 - loss: 0.6987 - val_AUC: 0.9416 - val_accuracy: 0.5284 - val_loss: 1.9778 - learning_rate: 1.2500e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 181ms/step - AUC: 0.9848 - accuracy: 0.6985 - loss: 0.6730 - val_AUC: 0.9409 - val_accuracy: 0.5368 - val_loss: 1.9638 - learning_rate: 1.2500e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 183ms/step - AUC: 0.9862 - accuracy: 0.7025 - loss: 0.6541 - val_AUC: 0.9411 - val_accuracy: 0.5336 - val_loss: 1.9743 - learning_rate: 1.2500e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 182ms/step - AUC: 0.9867 - accuracy: 0.7118 - loss: 0.6172 - val_AUC: 0.9396 - val_accuracy: 0.5340 - val_loss: 1.9645 - learning_rate: 1.2500e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 182ms/step - AUC: 0.9863 - accuracy: 0.7291 - loss: 0.5805 - val_AUC: 0.9402 - val_accuracy: 0.5401 - val_loss: 1.9618 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - AUC: 0.9880 - accuracy: 0.7251 - loss: 0.5715 - val_AUC: 0.9399 - val_accuracy: 0.5377 - val_loss: 1.9843 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 184ms/step - AUC: 0.9888 - accuracy: 0.7323 - loss: 0.5819 - val_AUC: 0.9405 - val_accuracy: 0.5391 - val_loss: 1.9838 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - AUC: 0.9890 - accuracy: 0.7360 - loss: 0.5376\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 182ms/step - AUC: 0.9890 - accuracy: 0.7360 - loss: 0.5376 - val_AUC: 0.9399 - val_accuracy: 0.5431 - val_loss: 1.9812 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 182ms/step - AUC: 0.9891 - accuracy: 0.7434 - loss: 0.5270 - val_AUC: 0.9400 - val_accuracy: 0.5468 - val_loss: 1.9684 - learning_rate: 6.2500e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 183ms/step - AUC: 0.9896 - accuracy: 0.7483 - loss: 0.5188 - val_AUC: 0.9378 - val_accuracy: 0.5522 - val_loss: 1.9704 - learning_rate: 6.2500e-05\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - AUC: 0.9412 - accuracy: 0.5410 - loss: 1.9479\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 664ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ MobileNetV2 â€“ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\mobilenetv2_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\mobilenetv2_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\mobilenetv2_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‰ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_baseline_confusion_matrix.png\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\mobilenetv2_baseline_accuracy_plot.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\mobilenetv2_baseline_predictions.csv\n",
      "âœ… Final validation accuracy:   54,01%\n",
      "ğŸ¯ Final validation AUC:        94,02%\n"
     ]
    }
   ],
   "source": [
    "results_mobilenetv2 = run_mobilenetv2_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"mobilenetv2_baseline\"\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_mobilenetv2['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_mobilenetv2['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"ğŸ“¦ MobileNetV2 â€“ Results Summary:\\n\")\n",
    "print(f\"ğŸ“ Model saved at:              {results_mobilenetv2['model_path']}\")\n",
    "print(f\"ğŸ“„ Training log:                {results_mobilenetv2['log_path']}\")\n",
    "print(f\"ğŸ“Š Classification report (CSV): {results_mobilenetv2['report_path']}\")\n",
    "print(f\"ğŸ§¯ Report heatmap (Top 20):     {results_mobilenetv2['heatmap_path']}\")\n",
    "print(f\"ğŸ“‰ Confusion matrix (full):     {results_mobilenetv2['confusion_matrix']}\")\n",
    "print(f\"ğŸ“ˆ Accuracy plot:               {results_mobilenetv2['accuracy_plot']}\")\n",
    "print(f\"ğŸ“‘ Predictions CSV:             {results_mobilenetv2['predictions_path']}\")\n",
    "print(f\"âœ… Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"ğŸ¯ Final validation AUC:        {val_auc_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f009c7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Baseline VGG16 Model</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa6b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vgg16_pipeline(train_gen, val_gen, test_gen, model_name=\"vgg16_baseline\", image_size=IMAGE_SIZE, epochs=EPOCHS_EFFECIENT):\n",
    "    models_dir = MODELS_DIR\n",
    "    logs_dir = LOGS_DIR\n",
    "    predictions_dir = PREDICTIONS_DIR\n",
    "    reports_dir = REPORTS_DIR\n",
    "    figures_dir = reports_dir / \"figures\"\n",
    "    for d in [models_dir, logs_dir, predictions_dir, figures_dir, reports_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_generator = train_gen\n",
    "    val_generator = val_gen\n",
    "    test_generator = test_gen\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    base_model = VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=5e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"AUC\"]\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "    csv_logger = CSVLogger(logs_dir / f\"{model_name}_training_log.csv\", append=False)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[csv_logger, early_stop, reduce_lr],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.h5\"\n",
    "    model_weights_path = models_dir / f\"{model_name}.weights.h5\"\n",
    "    model.save(model_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator)\n",
    "\n",
    "    acc_fig_path = figures_dir / f\"{model_name}_accuracy_plot.png\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_fig_path)\n",
    "    plt.close()\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = predictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    class_indices = test_generator.class_indices\n",
    "    inv_class_indices = {v: k for k, v in class_indices.items()}\n",
    "    predicted_labels = [inv_class_indices[i] for i in predicted_classes]\n",
    "    true_labels = [inv_class_indices[i] for i in true_classes]\n",
    "\n",
    "    report = classification_report(true_classes, predicted_classes, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = reports_dir / f\"{model_name}_classification_report.csv\"\n",
    "    report_df.to_csv(report_path)\n",
    "\n",
    "    heatmap_path = figures_dir / f\"{model_name}_classification_report_heatmap_top20.png\"\n",
    "    filtered_df = report_df.drop([\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "    top_20 = filtered_df.sort_values(\"support\", ascending=False).head(20)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_20[[\"precision\", \"recall\", \"f1-score\"]], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=0.5, annot_kws={\"size\": 9})\n",
    "    plt.title(\"Top 20 Classes â€“ Classification Report\", fontsize=14)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    plt.ylabel(\"Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "\n",
    "    top_labels = list(top_20.index)\n",
    "    label_to_index = {name: i for i, name in enumerate(class_indices.keys())}\n",
    "    top_indices = [label_to_index[l] for l in top_labels]\n",
    "    filtered_true = [i for i in true_classes if i in top_indices]\n",
    "    filtered_pred = [p for i, p in enumerate(predicted_classes) if true_classes[i] in top_indices]\n",
    "    cm = confusion_matrix(filtered_true, filtered_pred, labels=top_indices)\n",
    "    cm_labels = [list(class_indices.keys())[i] for i in top_indices]\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cm_labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=45, cmap='Blues', colorbar=True)\n",
    "    plt.title(\"Confusion Matrix â€“ Top 20 Classes\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    cm_path = figures_dir / f\"{model_name}_confusion_matrix_top20.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "    full_cm_path = figures_dir / f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(full_cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    results_df = pd.DataFrame({\n",
    "        \"filename\": filenames,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": predicted_labels\n",
    "    })\n",
    "    pred_path = predictions_dir / f\"{model_name}_predictions.csv\"\n",
    "    results_df.to_csv(pred_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"log_path\": logs_dir / f\"{model_name}_training_log.csv\",\n",
    "        \"report_path\": report_path,\n",
    "        \"heatmap_path\": heatmap_path,\n",
    "        \"confusion_matrix\": full_cm_path,\n",
    "        \"predictions_path\": pred_path,\n",
    "        \"accuracy_plot\": acc_fig_path,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_auc\": val_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f545c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - AUC: 0.5671 - accuracy: 0.0137 - loss: 5.3919 - val_AUC: 0.6888 - val_accuracy: 0.0785 - val_loss: 5.0912 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.7372 - accuracy: 0.0730 - loss: 4.6723 - val_AUC: 0.8381 - val_accuracy: 0.1666 - val_loss: 4.1743 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.8157 - accuracy: 0.1330 - loss: 4.0236 - val_AUC: 0.8716 - val_accuracy: 0.2055 - val_loss: 3.7052 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.8569 - accuracy: 0.1831 - loss: 3.5151 - val_AUC: 0.8849 - val_accuracy: 0.2374 - val_loss: 3.4733 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.8787 - accuracy: 0.2302 - loss: 3.1669 - val_AUC: 0.8935 - val_accuracy: 0.2628 - val_loss: 3.3274 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.8981 - accuracy: 0.2591 - loss: 2.9165 - val_AUC: 0.8971 - val_accuracy: 0.2728 - val_loss: 3.2247 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9063 - accuracy: 0.2866 - loss: 2.7117 - val_AUC: 0.9033 - val_accuracy: 0.2884 - val_loss: 3.0963 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9189 - accuracy: 0.3157 - loss: 2.5253 - val_AUC: 0.9065 - val_accuracy: 0.3127 - val_loss: 3.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9241 - accuracy: 0.3345 - loss: 2.3417 - val_AUC: 0.9050 - val_accuracy: 0.3206 - val_loss: 3.0099 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 1s/step - AUC: 0.9274 - accuracy: 0.3542 - loss: 2.2527 - val_AUC: 0.9050 - val_accuracy: 0.3292 - val_loss: 2.9346 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9350 - accuracy: 0.3800 - loss: 2.0980 - val_AUC: 0.9051 - val_accuracy: 0.3325 - val_loss: 2.9357 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9397 - accuracy: 0.3958 - loss: 1.9609 - val_AUC: 0.9089 - val_accuracy: 0.3420 - val_loss: 2.9035 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9417 - accuracy: 0.4102 - loss: 1.8770 - val_AUC: 0.9092 - val_accuracy: 0.3530 - val_loss: 2.8585 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9416 - accuracy: 0.4355 - loss: 1.7776 - val_AUC: 0.9077 - val_accuracy: 0.3465 - val_loss: 2.8806 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9475 - accuracy: 0.4445 - loss: 1.7319 - val_AUC: 0.9077 - val_accuracy: 0.3514 - val_loss: 2.8879 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - AUC: 0.9533 - accuracy: 0.4564 - loss: 1.6242\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9533 - accuracy: 0.4564 - loss: 1.6244 - val_AUC: 0.9056 - val_accuracy: 0.3507 - val_loss: 2.8731 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9542 - accuracy: 0.4794 - loss: 1.5513 - val_AUC: 0.9101 - val_accuracy: 0.3637 - val_loss: 2.8225 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9610 - accuracy: 0.4945 - loss: 1.4434 - val_AUC: 0.9094 - val_accuracy: 0.3788 - val_loss: 2.8090 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9588 - accuracy: 0.5023 - loss: 1.4123 - val_AUC: 0.9084 - val_accuracy: 0.3798 - val_loss: 2.7965 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9595 - accuracy: 0.5105 - loss: 1.3638 - val_AUC: 0.9097 - val_accuracy: 0.3760 - val_loss: 2.8016 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9620 - accuracy: 0.5226 - loss: 1.3348 - val_AUC: 0.9066 - val_accuracy: 0.3861 - val_loss: 2.7800 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9626 - accuracy: 0.5345 - loss: 1.2913 - val_AUC: 0.9065 - val_accuracy: 0.3889 - val_loss: 2.7758 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9649 - accuracy: 0.5292 - loss: 1.2612 - val_AUC: 0.9061 - val_accuracy: 0.3819 - val_loss: 2.7993 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9643 - accuracy: 0.5375 - loss: 1.2353 - val_AUC: 0.9083 - val_accuracy: 0.3912 - val_loss: 2.7923 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - AUC: 0.9700 - accuracy: 0.5544 - loss: 1.1736\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9700 - accuracy: 0.5544 - loss: 1.1737 - val_AUC: 0.9044 - val_accuracy: 0.3821 - val_loss: 2.7818 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9716 - accuracy: 0.5628 - loss: 1.1281 - val_AUC: 0.9054 - val_accuracy: 0.3893 - val_loss: 2.7882 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9716 - accuracy: 0.5673 - loss: 1.1227 - val_AUC: 0.9077 - val_accuracy: 0.3914 - val_loss: 2.7690 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9704 - accuracy: 0.5784 - loss: 1.1003 - val_AUC: 0.9065 - val_accuracy: 0.3959 - val_loss: 2.7542 - learning_rate: 1.2500e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9724 - accuracy: 0.5842 - loss: 1.0822 - val_AUC: 0.9059 - val_accuracy: 0.3877 - val_loss: 2.7660 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m265/265\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - AUC: 0.9750 - accuracy: 0.5791 - loss: 1.0473 - val_AUC: 0.9057 - val_accuracy: 0.3952 - val_loss: 2.7627 - learning_rate: 1.2500e-04\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 926ms/step - AUC: 0.9098 - accuracy: 0.3988 - loss: 2.7406\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 955ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Tiago Pedro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ VGG16 â€“ Results Summary:\n",
      "\n",
      "ğŸ“ Model saved at:              D:\\Repositories\\DL_EOLP\\models\\vgg16_baseline.h5\n",
      "ğŸ“„ Training log:                D:\\Repositories\\DL_EOLP\\output\\logs\\vgg16_baseline_training_log.csv\n",
      "ğŸ“Š Classification report (CSV): D:\\Repositories\\DL_EOLP\\reports\\vgg16_baseline_classification_report.csv\n",
      "ğŸ§¯ Report heatmap (Top 20):     D:\\Repositories\\DL_EOLP\\reports\\figures\\vgg16_baseline_classification_report_heatmap_top20.png\n",
      "ğŸ“‰ Confusion matrix (full):     D:\\Repositories\\DL_EOLP\\reports\\figures\\vgg16_baseline_confusion_matrix.png\n",
      "ğŸ“ˆ Accuracy plot:               D:\\Repositories\\DL_EOLP\\reports\\figures\\vgg16_baseline_accuracy_plot.png\n",
      "ğŸ“‘ Predictions CSV:             D:\\Repositories\\DL_EOLP\\output\\predictions\\vgg16_baseline_predictions.csv\n",
      "âœ… Final validation accuracy:   39,59%\n",
      "ğŸ¯ Final validation AUC:        90,65%\n"
     ]
    }
   ],
   "source": [
    "results_vgg16 = run_vgg16_pipeline(\n",
    "    train_gen=train_generator,\n",
    "    val_gen=val_generator,\n",
    "    test_gen=test_generator,\n",
    "    model_name=\"vgg16_baseline\"\n",
    ")\n",
    "\n",
    "val_accuracy_str = f\"{results_vgg16['val_accuracy']:.2%}\".replace(\".\", \",\")\n",
    "val_auc_str = f\"{results_vgg16['val_auc']:.2%}\".replace(\".\", \",\")\n",
    "\n",
    "print(\"ğŸ“¦ VGG16 â€“ Results Summary:\\n\")\n",
    "print(f\"ğŸ“ Model saved at:              {results_vgg16['model_path']}\")\n",
    "print(f\"ğŸ“„ Training log:                {results_vgg16['log_path']}\")\n",
    "print(f\"ğŸ“Š Classification report (CSV): {results_vgg16['report_path']}\")\n",
    "print(f\"ğŸ§¯ Report heatmap (Top 20):     {results_vgg16['heatmap_path']}\")\n",
    "print(f\"ğŸ“‰ Confusion matrix (full):     {results_vgg16['confusion_matrix']}\")\n",
    "print(f\"ğŸ“ˆ Accuracy plot:               {results_vgg16['accuracy_plot']}\")\n",
    "print(f\"ğŸ“‘ Predictions CSV:             {results_vgg16['predictions_path']}\")\n",
    "print(f\"âœ… Final validation accuracy:   {val_accuracy_str}\")\n",
    "print(f\"ğŸ¯ Final validation AUC:        {val_auc_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3536a9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 6px solid #27ae60; margin-left:40px; padding:10px; border-radius:10px; font-family:Arial, sans-serif; font-size:24px;\">\n",
    "  <h2 style=\"margin-top: 0; font-size:24px;\">ğŸ“¦ Resume Models Validation Accuracy</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-left:60px; padding:10px;\"> \n",
    "  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b12bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Avaliando modelo: EfficientNetB0\n",
      "ğŸ” Avaliando modelo: ResNet50\n",
      "ğŸ” Avaliando modelo: DenseNet121\n",
      "ğŸ” Avaliando modelo: MobileNetV2\n",
      "ğŸ” Avaliando modelo: VGG16\n",
      "\n",
      "ğŸ“Š Modelo comparativo salvo em: D:\\Repositories\\DL_EOLP\\reports\\model_comparison_summary.csv\n",
      "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚ Model          â”‚   Val Accuracy â”‚   Val AUC â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ MobileNetV2    â”‚         0.5424 â”‚    0.9485 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ VGG16          â”‚         0.3959 â”‚    0.9065 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ EfficientNetB0 â”‚         0.3698 â”‚    0.9324 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ DenseNet121    â”‚         0.1314 â”‚    0.7230 â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ ResNet50       â”‚         0.0916 â”‚    0.7585 â”‚\n",
      "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "model_paths = {\n",
    "    \"EfficientNetB0\": MODELS_DIR / \"efficientnetb0_baseline.h5\",\n",
    "    \"ResNet50\": MODELS_DIR / \"resnet50_baseline.h5\",\n",
    "    \"DenseNet121\": MODELS_DIR / \"densenet121_baseline.h5\",\n",
    "    \"MobileNetV2\": MODELS_DIR / \"mobilenetv2_baseline.h5\",\n",
    "    \"VGG16\": MODELS_DIR / \"vgg16_baseline.h5\"\n",
    "}\n",
    "\n",
    "models_summary = []\n",
    "for name, path in model_paths.items():\n",
    "    print(f\"ğŸ” Avaliando modelo: {name}\")\n",
    "    model = load_model(path, compile=False)\n",
    "    model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\", AUC(name=\"AUC\")])\n",
    "    val_loss, val_acc, val_auc = model.evaluate(val_generator, verbose=0)\n",
    "    models_summary.append({\n",
    "        \"Model\": name,\n",
    "        \"Val Accuracy\": val_acc,\n",
    "        \"Val AUC\": val_auc\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(models_summary)\n",
    "summary_df = summary_df.sort_values(by=\"Val Accuracy\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "summary_path = REPORTS_DIR / \"model_comparison_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"\\nğŸ“Š Modelo comparativo salvo em: {summary_path}\")\n",
    "print(tabulate(summary_df, headers=\"keys\", tablefmt=\"fancy_grid\", showindex=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c066ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiago Pedro\\AppData\\Local\\Temp\\ipykernel_12200\\3642737106.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=summary_df, x=\"Val Accuracy\", y=\"Model\", palette=\"crest\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=summary_df, x=\"Val Accuracy\", y=\"Model\", palette=\"crest\")\n",
    "plt.title(\"ComparaÃ§Ã£o de Accuracy de ValidaÃ§Ã£o por Modelo\", fontsize=16)\n",
    "plt.xlabel(\"Validation Accuracy\")\n",
    "plt.ylabel(\"Modelo\")\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = REPORTS_DIR / 'figures' / \"model_comparison_accuracy.png\"\n",
    "plt.savefig(plot_path)\n",
    "plt.close()\n",
    "\n",
    "image = Image.open(REPORTS_DIR / 'figures' / \"model_comparison_accuracy.png\")\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
